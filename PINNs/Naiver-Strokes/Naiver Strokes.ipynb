{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e51af0cf-d3ac-4dcb-b70f-db749b27ec42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animaton\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "506b8da6-aca4-46cb-9a61-12f73e7a2383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def coriolis_force(lat):\n",
    "    omega = 2 * np.pi / (24 * 60 * 3600)\n",
    "    f = 2 * omega * np.sin(lat)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7adcbcdb-57f8-4ff2-a069-87b440b1de1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = 10**(-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "042a9422-20d9-4b94-962f-fd05a5c62ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_train = 5000\n",
    "\n",
    "data = scipy.io.loadmat('navier_Stokes.mat')\n",
    "U_star = data['U_star']\n",
    "X_star = data['X_star']\n",
    "t_star = data['t']\n",
    "p_star = data['p_star']\n",
    "\n",
    "N = X_star.shape[0]\n",
    "M = t_star.shape[0]\n",
    "\n",
    "U = U_star[:, 0, :]\n",
    "V = U_star[:, 1, :]\n",
    "\n",
    "X = np.tile(X_star[:, 0:1], (1, t_star.shape[0]))  # (N, M)\n",
    "Y = np.tile(X_star[:, 1:2], (1, t_star.shape[0])) # (N, M)\n",
    "T = np.tile(t_star, (1, X_star.shape[0])).T # (N, M)\n",
    "\n",
    "XX = X.flatten()[:, None]\n",
    "YY = Y.flatten()[:, None]  \n",
    "TT = T.flatten()[:, None]  \n",
    "UU = U.flatten()[:, None]\n",
    "VV = V.flatten()[:, None]\n",
    "PP = p_star.flatten()[:, None]\n",
    "\n",
    "indices = np.random.choice(UU.shape[0], N_train, replace=False)\n",
    "x_train = torch.tensor(XX[indices], dtype=torch.float32, requires_grad=True)\n",
    "y_train = torch.tensor(YY[indices], dtype=torch.float32, requires_grad=True)\n",
    "t_train = torch.tensor(TT[indices], dtype=torch.float32, requires_grad=True)\n",
    "u_train = torch.tensor(UU[indices], dtype=torch.float32)\n",
    "v_train = torch.tensor(VV[indices], dtype=torch.float32)\n",
    "p_train = torch.tensor(PP[indices], dtype=torch.float32)\n",
    "\n",
    "x_test = X_star[:, 0:1]\n",
    "y_test = X_star[:, 1:2]\n",
    "t_test = np.ones((x_test.shape[0], x_test.shape[1])) # All ones so that when I animate, we go through all T, also appears smoother\n",
    "u_test = U_star[:, 0, :]\n",
    "v_test = U_star[:, 1, :]\n",
    "p_test = p_star\n",
    "\n",
    "x_test = torch.tensor(x_test, dtype=torch.float32, requires_grad=True)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32, requires_grad=True)\n",
    "t_test = torch.tensor(t_test, dtype=torch.float32, requires_grad=True)\n",
    "u_test = torch.tensor(u_test, dtype=torch.float32) # Used to create the residual\n",
    "v_test = torch.tensor(v_test, dtype=torch.float32)\n",
    "p_test = torch.tensor(p_test, dtype=torch.float32)\n",
    "\n",
    "X_plot = X_star[:, 0].reshape(50, 100)\n",
    "Y_plot = X_star[:, 1].reshape(50, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c8742aeb-df30-47c8-a24e-2856b9ec1116",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string expression part cannot include a backslash (1530806721.py, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 17\u001b[1;36m\u001b[0m\n\u001b[1;33m    ax[1].set_title(f'V velocity at t={t_st\\ar[frame][0]:.2f}')\u001b[0m\n\u001b[1;37m                                                              ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m f-string expression part cannot include a backslash\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "def update(frame):\n",
    "    ax[0].clear()\n",
    "    ax[1].clear()\n",
    "    ax[2].clear()\n",
    "    \n",
    "    U_plot = U_star[:, 0, frame].reshape(50, 100)\n",
    "    V_plot = U_star[:, 1, frame].reshape(50, 100)\n",
    "    P_plot = p_star[:, frame].reshape(50, 100)\n",
    "    \n",
    "    ax[0].contourf(X_plot, Y_plot, U_plot, levels = 20, cmap='jet') # Levels = 20 is necessary cuz gives error that contour lines not increasing\n",
    "    ax[1].contourf(X_plot, Y_plot, V_plot, levels = 20, cmap='jet')\n",
    "    ax[2].contourf(X_plot, Y_plot, P_plot, levels = 20, cmap='jet')\n",
    "     \n",
    "    ax[0].set_title(f'U velocity at t={t_star[frame][0]:.2f}')\n",
    "    ax[1].set_title(f'V velocity at t={t_st\\ar[frame][0]:.2f}')\n",
    "    ax[2].set_title(f'Pressure at t={t_star[frame][0]:.2f}')\n",
    "    ax[0].set_xlabel('x')\n",
    "    ax[0].set_ylabel('y')\n",
    "    ax[1].set_xlabel('x')\n",
    "    ax[1].set_ylabel('y')\n",
    "    ax[2].set_xlabel('x')\n",
    "    ax[2].set_ylabel('y')\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=t_star.shape[0], interval=1)\n",
    "#ani.save('navier_stokes_animation_true.gif') # Same graph when plot the test data\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b44ea045-b17c-44fe-89f6-409406efbf3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PINN, self).__init__()\n",
    "        self.fc1 = nn.Linear(3, 50) \n",
    "        self.fc2 = nn.Linear(50, 50) \n",
    "        self.fc3 = nn.Linear(50, 50) \n",
    "        self.fc4 = nn.Linear(50, 50) \n",
    "        self.fc5 = nn.Linear(50, 50) \n",
    "        self.fc6 = nn.Linear(50, 50) \n",
    "        self.fc7 = nn.Linear(50, 50) \n",
    "        self.fc8 = nn.Linear(50, 50) \n",
    "        self.fc9 = nn.Linear(50, 50) \n",
    "        self.fc10 = nn.Linear(50, 3)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.tanh(self.fc1(x))\n",
    "        x = torch.tanh(self.fc2(x))\n",
    "        x = torch.tanh(self.fc3(x))\n",
    "        x = torch.tanh(self.fc4(x))\n",
    "        x = torch.tanh(self.fc5(x))\n",
    "        x = torch.tanh(self.fc6(x))\n",
    "        x = torch.tanh(self.fc7(x))\n",
    "        x = torch.tanh(self.fc8(x))\n",
    "        x = torch.tanh(self.fc9(x))\n",
    "        x = self.fc10(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7903f2bb-b70c-4bec-beef-e96e9ca887e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_phys(f_x, f_y, c):\n",
    "    return torch.mean((f_x - 0)**2 + (f_y - 0)**2 + (c - 0)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "284ee8d4-0793-4bef-b7cd-eeafb3580d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_data(u, v, ssh): \n",
    "    return torch.mean((u - u_train)**2 + (v - v_train)**2 + (ssh - ssh_train)**2)\n",
    "    # return torch.mean((u - u_train)**2 + (v - v_train)**2 + (ssh - p_train)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9243986-335d-4907-862e-c01aab892623",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(x, y, t):\n",
    "    predict = model(torch.hstack((x, y, t))) # Allows x, y, and t to be in the computational graph instead of creating training_data\n",
    "    psi = predict[:, 0:1]\n",
    "    ssh = predict[:, 1:2]\n",
    "    \n",
    "    u = torch.autograd.grad(psi, y, grad_outputs=torch.ones_like(psi), create_graph=True)[0]\n",
    "    v = -1 * torch.autograd.grad(psi, x, grad_outputs=torch.ones_like(psi), create_graph=True)[0]\n",
    "\n",
    "    u_x = torch.autograd.grad(u, x, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "    u_xx = torch.autograd.grad(u_x, x, grad_outputs=torch.ones_like(u_x), create_graph=True)[0]\n",
    "    u_y = torch.autograd.grad(u, y, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "    u_yy = torch.autograd.grad(u_y, y, grad_outputs=torch.ones_like(u_y), create_graph=True)[0]\n",
    "\n",
    "    v_x = torch.autograd.grad(v, x, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
    "    v_xx = torch.autograd.grad(v_x, x, grad_outputs=torch.ones_like(v_x), create_graph=True)[0]\n",
    "    v_y = torch.autograd.grad(v, y, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
    "    v_yy = torch.autograd.grad(v_y, y, grad_outputs=torch.ones_like(v_y), create_graph=True)[0]\n",
    "\n",
    "    ssh_x = torch.autograd.grad(ssh, x, grad_outputs=torch.ones_like(ssh), create_graph=True)[0]\n",
    "    ssh_y = torch.autograd.grad(ssh, y, grad_outputs=torch.ones_like(ssh), create_graph=True)[0]\n",
    "\n",
    "    u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "    v_t = torch.autograd.grad(v, t, grad_outputs=torch.ones_like(v), create_graph=True)[0]\n",
    "\n",
    "    # f_x = u_t + u * u_x + v * u_y + ssh_x - nu * (u_xx + u_yy)\n",
    "    # f_y = v_t + u * v_x + v * v_y + ssh_y - nu * (v_xx + v_yy)\n",
    "\n",
    "    c = u_x + v_y\n",
    "\n",
    "    f_x = u_t + u * u_x + v * u_y + g * ssh_x - nu * (u_xx + u_yy)\n",
    "    f_y = v_t + u * v_x + v * v_y + g * ssh_y - nu * (v_xx + v_yy)\n",
    "\n",
    "    return u, v, ssh, f_x, f_y, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7a1f03d2-6c63-417e-9baa-7064d349dbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    u_pred, v_pred, ssh_pred, f_x, f_y, c = function(x_train, y_train, t_train)\n",
    "    loss = loss_data(u_pred, v_pred, ssh_pred) + loss_phys(f_x, f_y, c) \n",
    "    loss.backward()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "670e80a2-2093-4620-9d39-e430d702708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train(model, optimizer, num_epochs = 2000):\n",
    "    prev_loss = float('inf')  \n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        loss = optimizer.step(closure) # This is for LBFGS\n",
    "        print(f'Epoch [{epoch}/{num_epochs}], Loss: {loss.item()}')\n",
    "        if loss.item() >= prev_loss:\n",
    "            break # Stop iteration if loss isn't decreasing\n",
    "        prev_loss = loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7550a3b6-b936-428c-ab5e-78fbbafbc18b",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Loss: 22.1621036529541\n",
      "Epoch [2/1000], Loss: 21.363168716430664\n",
      "Epoch [3/1000], Loss: 19.46809196472168\n",
      "Epoch [4/1000], Loss: 16.031036376953125\n",
      "Epoch [5/1000], Loss: 13.639433860778809\n",
      "Epoch [6/1000], Loss: 11.999612808227539\n",
      "Epoch [7/1000], Loss: 10.751105308532715\n",
      "Epoch [8/1000], Loss: 9.715580940246582\n",
      "Epoch [9/1000], Loss: 8.658815383911133\n",
      "Epoch [10/1000], Loss: 7.36850643157959\n",
      "Epoch [11/1000], Loss: 6.331462383270264\n",
      "Epoch [12/1000], Loss: 5.6038031578063965\n",
      "Epoch [13/1000], Loss: 5.05152702331543\n",
      "Epoch [14/1000], Loss: 4.556077003479004\n",
      "Epoch [15/1000], Loss: 4.072875022888184\n",
      "Epoch [16/1000], Loss: 3.6936779022216797\n",
      "Epoch [17/1000], Loss: 3.411155939102173\n",
      "Epoch [18/1000], Loss: 3.1782002449035645\n",
      "Epoch [19/1000], Loss: 2.9285409450531006\n",
      "Epoch [20/1000], Loss: 2.7094054222106934\n",
      "Epoch [21/1000], Loss: 2.5221800804138184\n",
      "Epoch [22/1000], Loss: 2.3220877647399902\n",
      "Epoch [23/1000], Loss: 2.170361042022705\n",
      "Epoch [24/1000], Loss: 2.0673441886901855\n",
      "Epoch [25/1000], Loss: 1.9706735610961914\n",
      "Epoch [26/1000], Loss: 1.8753445148468018\n",
      "Epoch [27/1000], Loss: 1.8029882907867432\n",
      "Epoch [28/1000], Loss: 1.74785578250885\n",
      "Epoch [29/1000], Loss: 1.7022333145141602\n",
      "Epoch [30/1000], Loss: 1.6632863283157349\n",
      "Epoch [31/1000], Loss: 1.6301497220993042\n",
      "Epoch [32/1000], Loss: 1.5886993408203125\n",
      "Epoch [33/1000], Loss: 1.5433374643325806\n",
      "Epoch [34/1000], Loss: 1.5148463249206543\n",
      "Epoch [35/1000], Loss: 1.4742298126220703\n",
      "Epoch [36/1000], Loss: 1.4412362575531006\n",
      "Epoch [37/1000], Loss: 1.4173228740692139\n",
      "Epoch [38/1000], Loss: 1.398249864578247\n",
      "Epoch [39/1000], Loss: 1.3807263374328613\n",
      "Epoch [40/1000], Loss: 1.3625115156173706\n",
      "Epoch [41/1000], Loss: 1.3414556980133057\n",
      "Epoch [42/1000], Loss: 1.318922996520996\n",
      "Epoch [43/1000], Loss: 1.2957093715667725\n",
      "Epoch [44/1000], Loss: 1.2657978534698486\n",
      "Epoch [45/1000], Loss: 1.2289526462554932\n",
      "Epoch [46/1000], Loss: 1.1931402683258057\n",
      "Epoch [47/1000], Loss: 1.1563150882720947\n",
      "Epoch [48/1000], Loss: 1.1166318655014038\n",
      "Epoch [49/1000], Loss: 1.0668200254440308\n",
      "Epoch [50/1000], Loss: 1.0139491558074951\n",
      "Epoch [51/1000], Loss: 0.9697245955467224\n",
      "Epoch [52/1000], Loss: 0.9310677647590637\n",
      "Epoch [53/1000], Loss: 0.8958226442337036\n",
      "Epoch [54/1000], Loss: 0.8623867034912109\n",
      "Epoch [55/1000], Loss: 0.8316880464553833\n",
      "Epoch [56/1000], Loss: 0.8041385412216187\n",
      "Epoch [57/1000], Loss: 0.7773311734199524\n",
      "Epoch [58/1000], Loss: 0.7538094520568848\n",
      "Epoch [59/1000], Loss: 0.7339304089546204\n",
      "Epoch [60/1000], Loss: 0.7168421149253845\n",
      "Epoch [61/1000], Loss: 0.702759861946106\n",
      "Epoch [62/1000], Loss: 0.6891734600067139\n",
      "Epoch [63/1000], Loss: 0.6765390634536743\n",
      "Epoch [64/1000], Loss: 0.6664221286773682\n",
      "Epoch [65/1000], Loss: 0.6582683324813843\n",
      "Epoch [66/1000], Loss: 0.6516899466514587\n",
      "Epoch [67/1000], Loss: 0.6462308764457703\n",
      "Epoch [68/1000], Loss: 0.6408262848854065\n",
      "Epoch [69/1000], Loss: 0.6356582045555115\n",
      "Epoch [70/1000], Loss: 0.6318140625953674\n",
      "Epoch [71/1000], Loss: 0.6287345886230469\n",
      "Epoch [72/1000], Loss: 0.6259130239486694\n",
      "Epoch [73/1000], Loss: 0.6230029463768005\n",
      "Epoch [74/1000], Loss: 0.620627224445343\n",
      "Epoch [75/1000], Loss: 0.6184028387069702\n",
      "Epoch [76/1000], Loss: 0.6159539818763733\n",
      "Epoch [77/1000], Loss: 0.6146383285522461\n",
      "Epoch [78/1000], Loss: 0.6136993765830994\n",
      "Epoch [79/1000], Loss: 0.6128641366958618\n",
      "Epoch [80/1000], Loss: 0.611689567565918\n",
      "Epoch [81/1000], Loss: 0.6095491051673889\n",
      "Epoch [82/1000], Loss: 0.6079660058021545\n",
      "Epoch [83/1000], Loss: 0.6067039370536804\n",
      "Epoch [84/1000], Loss: 0.6055424213409424\n",
      "Epoch [85/1000], Loss: 0.6044400930404663\n",
      "Epoch [86/1000], Loss: 0.603264570236206\n",
      "Epoch [87/1000], Loss: 0.6018952131271362\n",
      "Epoch [88/1000], Loss: 0.6004708409309387\n",
      "Epoch [89/1000], Loss: 0.5991151332855225\n",
      "Epoch [90/1000], Loss: 0.597791850566864\n",
      "Epoch [91/1000], Loss: 0.5963535904884338\n",
      "Epoch [92/1000], Loss: 0.5943513512611389\n",
      "Epoch [93/1000], Loss: 0.5917350649833679\n",
      "Epoch [94/1000], Loss: 0.5901305675506592\n",
      "Epoch [95/1000], Loss: 0.5889323353767395\n",
      "Epoch [96/1000], Loss: 0.5879800915718079\n",
      "Epoch [97/1000], Loss: 0.5871927738189697\n",
      "Epoch [98/1000], Loss: 0.5864512324333191\n",
      "Epoch [99/1000], Loss: 0.5856897234916687\n",
      "Epoch [100/1000], Loss: 0.5848982930183411\n",
      "Epoch [101/1000], Loss: 0.5840089917182922\n",
      "Epoch [102/1000], Loss: 0.5827290415763855\n",
      "Epoch [103/1000], Loss: 0.5812336802482605\n",
      "Epoch [104/1000], Loss: 0.5799338221549988\n",
      "Epoch [105/1000], Loss: 0.5788465738296509\n",
      "Epoch [106/1000], Loss: 0.5778762102127075\n",
      "Epoch [107/1000], Loss: 0.5767199993133545\n",
      "Epoch [108/1000], Loss: 0.5758008360862732\n",
      "Epoch [109/1000], Loss: 0.57468181848526\n",
      "Epoch [110/1000], Loss: 0.5732938051223755\n",
      "Epoch [111/1000], Loss: 0.5722430944442749\n",
      "Epoch [112/1000], Loss: 0.5712500810623169\n",
      "Epoch [113/1000], Loss: 0.5703152418136597\n",
      "Epoch [114/1000], Loss: 0.5694867372512817\n",
      "Epoch [115/1000], Loss: 0.5686305165290833\n",
      "Epoch [116/1000], Loss: 0.567808210849762\n",
      "Epoch [117/1000], Loss: 0.5669367909431458\n",
      "Epoch [118/1000], Loss: 0.5657811164855957\n",
      "Epoch [119/1000], Loss: 0.5645430684089661\n",
      "Epoch [120/1000], Loss: 0.5634505152702332\n",
      "Epoch [121/1000], Loss: 0.5624624490737915\n",
      "Epoch [122/1000], Loss: 0.5616115927696228\n",
      "Epoch [123/1000], Loss: 0.5608368515968323\n",
      "Epoch [124/1000], Loss: 0.5601022243499756\n",
      "Epoch [125/1000], Loss: 0.5594309568405151\n",
      "Epoch [126/1000], Loss: 0.5588040351867676\n",
      "Epoch [127/1000], Loss: 0.5581706166267395\n",
      "Epoch [128/1000], Loss: 0.5574877858161926\n",
      "Epoch [129/1000], Loss: 0.5568331480026245\n",
      "Epoch [130/1000], Loss: 0.5561925768852234\n",
      "Epoch [131/1000], Loss: 0.5555517673492432\n",
      "Epoch [132/1000], Loss: 0.5549221038818359\n",
      "Epoch [133/1000], Loss: 0.5542972087860107\n",
      "Epoch [134/1000], Loss: 0.5536725521087646\n",
      "Epoch [135/1000], Loss: 0.5529892444610596\n",
      "Epoch [136/1000], Loss: 0.5523789525032043\n",
      "Epoch [137/1000], Loss: 0.5517372488975525\n",
      "Epoch [138/1000], Loss: 0.5510962009429932\n",
      "Epoch [139/1000], Loss: 0.5504480600357056\n",
      "Epoch [140/1000], Loss: 0.5497733950614929\n",
      "Epoch [141/1000], Loss: 0.5490903854370117\n",
      "Epoch [142/1000], Loss: 0.5484218597412109\n",
      "Epoch [143/1000], Loss: 0.5477152466773987\n",
      "Epoch [144/1000], Loss: 0.5470203757286072\n",
      "Epoch [145/1000], Loss: 0.5462914109230042\n",
      "Epoch [146/1000], Loss: 0.5455307960510254\n",
      "Epoch [147/1000], Loss: 0.5447002053260803\n",
      "Epoch [148/1000], Loss: 0.5437712073326111\n",
      "Epoch [149/1000], Loss: 0.5428225994110107\n",
      "Epoch [150/1000], Loss: 0.5418826341629028\n",
      "Epoch [151/1000], Loss: 0.5409292578697205\n",
      "Epoch [152/1000], Loss: 0.5401503443717957\n",
      "Epoch [153/1000], Loss: 0.5393837094306946\n",
      "Epoch [154/1000], Loss: 0.5385181903839111\n",
      "Epoch [155/1000], Loss: 0.5373592376708984\n",
      "Epoch [156/1000], Loss: 0.536051869392395\n",
      "Epoch [157/1000], Loss: 0.5348010063171387\n",
      "Epoch [158/1000], Loss: 0.5335522294044495\n",
      "Epoch [159/1000], Loss: 0.5323459506034851\n",
      "Epoch [160/1000], Loss: 0.5312244296073914\n",
      "Epoch [161/1000], Loss: 0.5301735997200012\n",
      "Epoch [162/1000], Loss: 0.5290669202804565\n",
      "Epoch [163/1000], Loss: 0.5279827117919922\n",
      "Epoch [164/1000], Loss: 0.5269418954849243\n",
      "Epoch [165/1000], Loss: 0.525955319404602\n",
      "Epoch [166/1000], Loss: 0.5250035524368286\n",
      "Epoch [167/1000], Loss: 0.5240349769592285\n",
      "Epoch [168/1000], Loss: 0.5231884717941284\n",
      "Epoch [169/1000], Loss: 0.5223178863525391\n",
      "Epoch [170/1000], Loss: 0.5213496685028076\n",
      "Epoch [171/1000], Loss: 0.5204151272773743\n",
      "Epoch [172/1000], Loss: 0.5195164680480957\n",
      "Epoch [173/1000], Loss: 0.5185692310333252\n",
      "Epoch [174/1000], Loss: 0.5175701379776001\n",
      "Epoch [175/1000], Loss: 0.5165796875953674\n",
      "Epoch [176/1000], Loss: 0.5155733227729797\n",
      "Epoch [177/1000], Loss: 0.5144751071929932\n",
      "Epoch [178/1000], Loss: 0.5133208632469177\n",
      "Epoch [179/1000], Loss: 0.5123148560523987\n",
      "Epoch [180/1000], Loss: 0.5113463997840881\n",
      "Epoch [181/1000], Loss: 0.5103914737701416\n",
      "Epoch [182/1000], Loss: 0.5094638466835022\n",
      "Epoch [183/1000], Loss: 0.5085120797157288\n",
      "Epoch [184/1000], Loss: 0.5075250267982483\n",
      "Epoch [185/1000], Loss: 0.5064194798469543\n",
      "Epoch [186/1000], Loss: 0.5051783919334412\n",
      "Epoch [187/1000], Loss: 0.5039774775505066\n",
      "Epoch [188/1000], Loss: 0.5026215314865112\n",
      "Epoch [189/1000], Loss: 0.5012993812561035\n",
      "Epoch [190/1000], Loss: 0.5001780986785889\n",
      "Epoch [191/1000], Loss: 0.4991195499897003\n",
      "Epoch [192/1000], Loss: 0.4980737268924713\n",
      "Epoch [193/1000], Loss: 0.49703332781791687\n",
      "Epoch [194/1000], Loss: 0.496084988117218\n",
      "Epoch [195/1000], Loss: 0.4952089190483093\n",
      "Epoch [196/1000], Loss: 0.4943208396434784\n",
      "Epoch [197/1000], Loss: 0.49344006180763245\n",
      "Epoch [198/1000], Loss: 0.4925493896007538\n",
      "Epoch [199/1000], Loss: 0.4917339086532593\n",
      "Epoch [200/1000], Loss: 0.49096643924713135\n",
      "Epoch [201/1000], Loss: 0.4902448058128357\n",
      "Epoch [202/1000], Loss: 0.48956000804901123\n",
      "Epoch [203/1000], Loss: 0.48891735076904297\n",
      "Epoch [204/1000], Loss: 0.48829135298728943\n",
      "Epoch [205/1000], Loss: 0.4876789450645447\n",
      "Epoch [206/1000], Loss: 0.4870814085006714\n",
      "Epoch [207/1000], Loss: 0.4864865243434906\n",
      "Epoch [208/1000], Loss: 0.4858506917953491\n",
      "Epoch [209/1000], Loss: 0.4852587878704071\n",
      "Epoch [210/1000], Loss: 0.4846734404563904\n",
      "Epoch [211/1000], Loss: 0.4841298758983612\n",
      "Epoch [212/1000], Loss: 0.4830915927886963\n",
      "Epoch [213/1000], Loss: 0.48247048258781433\n",
      "Epoch [214/1000], Loss: 0.4818747937679291\n",
      "Epoch [215/1000], Loss: 0.4813781678676605\n",
      "Epoch [216/1000], Loss: 0.48089852929115295\n",
      "Epoch [217/1000], Loss: 0.480462908744812\n",
      "Epoch [218/1000], Loss: 0.48004838824272156\n",
      "Epoch [219/1000], Loss: 0.4796079695224762\n",
      "Epoch [220/1000], Loss: 0.4792057275772095\n",
      "Epoch [221/1000], Loss: 0.4788261651992798\n",
      "Epoch [222/1000], Loss: 0.4784453809261322\n",
      "Epoch [223/1000], Loss: 0.47808077931404114\n",
      "Epoch [224/1000], Loss: 0.4777170419692993\n",
      "Epoch [225/1000], Loss: 0.4773600697517395\n",
      "Epoch [226/1000], Loss: 0.47701308131217957\n",
      "Epoch [227/1000], Loss: 0.4766627550125122\n",
      "Epoch [228/1000], Loss: 0.47628533840179443\n",
      "Epoch [229/1000], Loss: 0.47595638036727905\n",
      "Epoch [230/1000], Loss: 0.47561806440353394\n",
      "Epoch [231/1000], Loss: 0.475262850522995\n",
      "Epoch [232/1000], Loss: 0.4749184846878052\n",
      "Epoch [233/1000], Loss: 0.47426000237464905\n",
      "Epoch [234/1000], Loss: 0.4738881289958954\n",
      "Epoch [235/1000], Loss: 0.4735264778137207\n",
      "Epoch [236/1000], Loss: 0.47315698862075806\n",
      "Epoch [237/1000], Loss: 0.4727814197540283\n",
      "Epoch [238/1000], Loss: 0.4724368751049042\n",
      "Epoch [239/1000], Loss: 0.47210830450057983\n",
      "Epoch [240/1000], Loss: 0.47178155183792114\n",
      "Epoch [241/1000], Loss: 0.4714426100254059\n",
      "Epoch [242/1000], Loss: 0.47112101316452026\n",
      "Epoch [243/1000], Loss: 0.4707566499710083\n",
      "Epoch [244/1000], Loss: 0.47040748596191406\n",
      "Epoch [245/1000], Loss: 0.47009289264678955\n",
      "Epoch [246/1000], Loss: 0.4698105752468109\n",
      "Epoch [247/1000], Loss: 0.4695064425468445\n",
      "Epoch [248/1000], Loss: 0.4692579209804535\n",
      "Epoch [249/1000], Loss: 0.4689236879348755\n",
      "Epoch [250/1000], Loss: 0.46868860721588135\n",
      "Epoch [251/1000], Loss: 0.46846824884414673\n",
      "Epoch [252/1000], Loss: 0.46821242570877075\n",
      "Epoch [253/1000], Loss: 0.4679636061191559\n",
      "Epoch [254/1000], Loss: 0.46776676177978516\n",
      "Epoch [255/1000], Loss: 0.4675999879837036\n",
      "Epoch [256/1000], Loss: 0.4674142301082611\n",
      "Epoch [257/1000], Loss: 0.4672534763813019\n",
      "Epoch [258/1000], Loss: 0.46710047125816345\n",
      "Epoch [259/1000], Loss: 0.46657583117485046\n",
      "Epoch [260/1000], Loss: 0.4663701355457306\n",
      "Epoch [261/1000], Loss: 0.46624478697776794\n",
      "Epoch [262/1000], Loss: 0.46606671810150146\n",
      "Epoch [263/1000], Loss: 0.46592268347740173\n",
      "Epoch [264/1000], Loss: 0.46580037474632263\n",
      "Epoch [265/1000], Loss: 0.4656604528427124\n",
      "Epoch [266/1000], Loss: 0.46558159589767456\n",
      "Epoch [267/1000], Loss: 0.4654940366744995\n",
      "Epoch [268/1000], Loss: 0.46538594365119934\n",
      "Epoch [269/1000], Loss: 0.4652959108352661\n",
      "Epoch [270/1000], Loss: 0.4651040732860565\n",
      "Epoch [271/1000], Loss: 0.46500614285469055\n",
      "Epoch [272/1000], Loss: 0.46491387486457825\n",
      "Epoch [273/1000], Loss: 0.46481797099113464\n",
      "Epoch [274/1000], Loss: 0.464749276638031\n",
      "Epoch [275/1000], Loss: 0.4646628499031067\n",
      "Epoch [276/1000], Loss: 0.46457433700561523\n",
      "Epoch [277/1000], Loss: 0.4644937813282013\n",
      "Epoch [278/1000], Loss: 0.4644075334072113\n",
      "Epoch [279/1000], Loss: 0.4643235504627228\n",
      "Epoch [280/1000], Loss: 0.46424850821495056\n",
      "Epoch [281/1000], Loss: 0.464181512594223\n",
      "Epoch [282/1000], Loss: 0.46411487460136414\n",
      "Epoch [283/1000], Loss: 0.4640403389930725\n",
      "Epoch [284/1000], Loss: 0.4639761745929718\n",
      "Epoch [285/1000], Loss: 0.46391552686691284\n",
      "Epoch [286/1000], Loss: 0.4638598561286926\n",
      "Epoch [287/1000], Loss: 0.46380728483200073\n",
      "Epoch [288/1000], Loss: 0.4637567698955536\n",
      "Epoch [289/1000], Loss: 0.4637090265750885\n",
      "Epoch [290/1000], Loss: 0.4636658728122711\n",
      "Epoch [291/1000], Loss: 0.46361303329467773\n",
      "Epoch [292/1000], Loss: 0.4635738730430603\n",
      "Epoch [293/1000], Loss: 0.46354007720947266\n",
      "Epoch [294/1000], Loss: 0.46350446343421936\n",
      "Epoch [295/1000], Loss: 0.46347323060035706\n",
      "Epoch [296/1000], Loss: 0.46344083547592163\n",
      "Epoch [297/1000], Loss: 0.4634115993976593\n",
      "Epoch [298/1000], Loss: 0.4633822739124298\n",
      "Epoch [299/1000], Loss: 0.4633527994155884\n",
      "Epoch [300/1000], Loss: 0.46332284808158875\n",
      "Epoch [301/1000], Loss: 0.46328961849212646\n",
      "Epoch [302/1000], Loss: 0.46326327323913574\n",
      "Epoch [303/1000], Loss: 0.46323803067207336\n",
      "Epoch [304/1000], Loss: 0.4631902575492859\n",
      "Epoch [305/1000], Loss: 0.4631660580635071\n",
      "Epoch [306/1000], Loss: 0.46314388513565063\n",
      "Epoch [307/1000], Loss: 0.463125616312027\n",
      "Epoch [308/1000], Loss: 0.4631078243255615\n",
      "Epoch [309/1000], Loss: 0.4630902409553528\n",
      "Epoch [310/1000], Loss: 0.4630732834339142\n",
      "Epoch [311/1000], Loss: 0.4630568325519562\n",
      "Epoch [312/1000], Loss: 0.46304070949554443\n",
      "Epoch [313/1000], Loss: 0.46302488446235657\n",
      "Epoch [314/1000], Loss: 0.4630080759525299\n",
      "Epoch [315/1000], Loss: 0.46299225091934204\n",
      "Epoch [316/1000], Loss: 0.4629766345024109\n",
      "Epoch [317/1000], Loss: 0.4629615545272827\n",
      "Epoch [318/1000], Loss: 0.46294689178466797\n",
      "Epoch [319/1000], Loss: 0.46293261647224426\n",
      "Epoch [320/1000], Loss: 0.4629186689853668\n",
      "Epoch [321/1000], Loss: 0.4629051685333252\n",
      "Epoch [322/1000], Loss: 0.462892085313797\n",
      "Epoch [323/1000], Loss: 0.4628793001174927\n",
      "Epoch [324/1000], Loss: 0.4628671109676361\n",
      "Epoch [325/1000], Loss: 0.4628554880619049\n",
      "Epoch [326/1000], Loss: 0.4628441333770752\n",
      "Epoch [327/1000], Loss: 0.46283307671546936\n",
      "Epoch [328/1000], Loss: 0.46282249689102173\n",
      "Epoch [329/1000], Loss: 0.462812602519989\n",
      "Epoch [330/1000], Loss: 0.4628029465675354\n",
      "Epoch [331/1000], Loss: 0.4627937376499176\n",
      "Epoch [332/1000], Loss: 0.46278491616249084\n",
      "Epoch [333/1000], Loss: 0.4627765715122223\n",
      "Epoch [334/1000], Loss: 0.4627685844898224\n",
      "Epoch [335/1000], Loss: 0.46276113390922546\n",
      "Epoch [336/1000], Loss: 0.4627538323402405\n",
      "Epoch [337/1000], Loss: 0.46274712681770325\n",
      "Epoch [338/1000], Loss: 0.4627406597137451\n",
      "Epoch [339/1000], Loss: 0.4627343416213989\n",
      "Epoch [340/1000], Loss: 0.4627285897731781\n",
      "Epoch [341/1000], Loss: 0.46272310614585876\n",
      "Epoch [342/1000], Loss: 0.4627179205417633\n",
      "Epoch [343/1000], Loss: 0.46271300315856934\n",
      "Epoch [344/1000], Loss: 0.46270838379859924\n",
      "Epoch [345/1000], Loss: 0.46270397305488586\n",
      "Epoch [346/1000], Loss: 0.4626997411251068\n",
      "Epoch [347/1000], Loss: 0.4626957178115845\n",
      "Epoch [348/1000], Loss: 0.46269211173057556\n",
      "Epoch [349/1000], Loss: 0.462688684463501\n",
      "Epoch [350/1000], Loss: 0.4626855254173279\n",
      "Epoch [351/1000], Loss: 0.46268230676651\n",
      "Epoch [352/1000], Loss: 0.46267932653427124\n",
      "Epoch [353/1000], Loss: 0.4626765549182892\n",
      "Epoch [354/1000], Loss: 0.4626740515232086\n",
      "Epoch [355/1000], Loss: 0.46267181634902954\n",
      "Epoch [356/1000], Loss: 0.4626697599887848\n",
      "Epoch [357/1000], Loss: 0.4626675844192505\n",
      "Epoch [358/1000], Loss: 0.4626655578613281\n",
      "Epoch [359/1000], Loss: 0.4626637399196625\n",
      "Epoch [360/1000], Loss: 0.46266189217567444\n",
      "Epoch [361/1000], Loss: 0.4626615643501282\n",
      "Epoch [362/1000], Loss: 0.46265965700149536\n",
      "Epoch [363/1000], Loss: 0.46265771985054016\n",
      "Epoch [364/1000], Loss: 0.4626558721065521\n",
      "Epoch [365/1000], Loss: 0.4626542031764984\n",
      "Epoch [366/1000], Loss: 0.4626525342464447\n",
      "Epoch [367/1000], Loss: 0.4626513719558716\n",
      "Epoch [368/1000], Loss: 0.4626510441303253\n",
      "Epoch [369/1000], Loss: 0.4626500904560089\n",
      "Epoch [370/1000], Loss: 0.46264952421188354\n",
      "Epoch [371/1000], Loss: 0.46264901757240295\n",
      "Epoch [372/1000], Loss: 0.4626472294330597\n",
      "Epoch [373/1000], Loss: 0.46264711022377014\n",
      "Epoch [374/1000], Loss: 0.46264535188674927\n",
      "Epoch [375/1000], Loss: 0.4626440703868866\n",
      "Epoch [376/1000], Loss: 0.4626427888870239\n",
      "Epoch [377/1000], Loss: 0.4626410901546478\n",
      "Epoch [378/1000], Loss: 0.46263954043388367\n",
      "Epoch [379/1000], Loss: 0.4626387059688568\n",
      "Epoch [380/1000], Loss: 0.4626384675502777\n",
      "Epoch [381/1000], Loss: 0.4626375138759613\n",
      "Epoch [382/1000], Loss: 0.46263593435287476\n",
      "Epoch [383/1000], Loss: 0.462634414434433\n",
      "Epoch [384/1000], Loss: 0.46263375878334045\n",
      "Epoch [385/1000], Loss: 0.4626336097717285\n",
      "Epoch [386/1000], Loss: 0.46263226866722107\n",
      "Epoch [387/1000], Loss: 0.46263083815574646\n",
      "Epoch [388/1000], Loss: 0.46263083815574646\n"
     ]
    }
   ],
   "source": [
    "# Initialize model and optimizer\n",
    "model = PINN()\n",
    "\n",
    "# LBFGS optimizer best for handling second derivative information and small datasets\n",
    "# requires a closure() to perform the loss function multiple times, and be consistent\n",
    "# optimizer = optim.LBFGS(model.parameters(), lr = 1)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "# Train the model\n",
    "train(model, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98db551e-7826-4fb6-a4b2-bbec8898aa20",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "u_pred, v_pred, p_pred, _ , _, _ = function(x_test, y_test, t_test * t_star[0][0])\n",
    "\n",
    "U_plot = u_pred.detach().numpy().reshape(50, 100)\n",
    "V_plot = v_pred.detach().numpy().reshape(50, 100)\n",
    "P_plot = p_pred.detach().numpy().reshape(50, 100)\n",
    "\n",
    "ax[0].contourf(X_plot, Y_plot, U_plot, cmap='jet')\n",
    "ax[1].contourf(X_plot, Y_plot, V_plot, cmap='jet')\n",
    "ax[2].contourf(X_plot, Y_plot, P_plot, cmap='jet')\n",
    "\n",
    "c1 = ax[0].contourf(X_plot, Y_plot, U_plot, cmap='jet')\n",
    "c2 = ax[1].contourf(X_plot, Y_plot, V_plot, cmap='jet')\n",
    "c3 = ax[2].contourf(X_plot, Y_plot, P_plot, cmap='jet')\n",
    "\n",
    "cb1 = fig.colorbar(c1, ax=ax[0])\n",
    "cb2 = fig.colorbar(c2, ax=ax[1])\n",
    "cb3 = fig.colorbar(c3, ax=ax[2])\n",
    "\n",
    "def update(frame):\n",
    "    ax[0].clear()\n",
    "    ax[1].clear()\n",
    "    ax[2].clear()\n",
    "\n",
    "    u_pred, v_pred, p_pred, _ , _, _ = function(x_test, y_test, t_test * t_star[frame][0])\n",
    "    \n",
    "    U_plot = u_pred.detach().numpy().reshape(50, 100)\n",
    "    V_plot = v_pred.detach().numpy().reshape(50, 100)\n",
    "    P_plot = p_pred.detach().numpy().reshape(50, 100)\n",
    "\n",
    "    ax[0].contourf(X_plot, Y_plot, U_plot, cmap='jet')\n",
    "    ax[1].contourf(X_plot, Y_plot, V_plot, cmap='jet')\n",
    "    ax[2].contourf(X_plot, Y_plot, P_plot, cmap='jet')\n",
    "    \n",
    "    ax[0].set_title(f'U velocity at t={t_star[frame][0]:.2f}')\n",
    "    ax[1].set_title(f'V velocity at t={t_star[frame][0]:.2f}')\n",
    "    ax[2].set_title(f'Pressure at t={t_star[frame][0]:.2f}')\n",
    "    ax[0].set_xlabel('y')\n",
    "    ax[0].set_ylabel('x')\n",
    "    ax[1].set_xlabel('y')\n",
    "    ax[1].set_ylabel('x')\n",
    "    ax[2].set_xlabel('y')\n",
    "    ax[2].set_ylabel('x')\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=t_star.shape[0], interval=1)\n",
    "#ani.save('navier_stokes_animation_pred.gif')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a6993-1718-4035-8f08-1c9ebc9a5689",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 3, figsize=(18, 6))\n",
    "\n",
    "u_pred, v_pred, p_pred, _ , _ , _ = function(x_test, y_test, t_test * t_star[0][0])\n",
    "\n",
    "U_plot = ((u_test[:, 0:1] - u_pred.detach().numpy())**2).reshape(50, 100) # [:, frame:frame + 1] to get extra dim. **2 to see differences\n",
    "V_plot = ((v_test[:, 0:1] - v_pred.detach().numpy())**2).reshape(50, 100)\n",
    "P_plot = ((p_test[:, 0:1] - p_pred.detach().numpy())**2).reshape(50, 100)\n",
    "\n",
    "ax[0].contourf(X_plot, Y_plot, U_plot, cmap='jet')\n",
    "ax[1].contourf(X_plot, Y_plot, V_plot, cmap='jet')\n",
    "ax[2].contourf(X_plot, Y_plot, P_plot, cmap='jet')\n",
    "\n",
    "c1 = ax[0].contourf(X_plot, Y_plot, U_plot, cmap='jet')\n",
    "c2 = ax[1].contourf(X_plot, Y_plot, V_plot, cmap='jet')\n",
    "c3 = ax[2].contourf(X_plot, Y_plot, P_plot, cmap='jet')\n",
    "\n",
    "cb1 = fig.colorbar(c1, ax=ax[0])\n",
    "cb2 = fig.colorbar(c2, ax=ax[1])\n",
    "cb3 = fig.colorbar(c3, ax=ax[2])\n",
    "\n",
    "def update(frame):\n",
    "    ax[0].clear()\n",
    "    ax[1].clear()\n",
    "    ax[2].clear()\n",
    "\n",
    "    u_pred, v_pred, p_pred, _ , _ , _ = function(x_test, y_test, t_test * t_star[frame][0])\n",
    "\n",
    "    U_plot = ((u_test[:, frame:frame + 1] - u_pred.detach().numpy())**2).reshape(50, 100) # [:, frame:frame + 1] to get extra dim. **2 to see differences\n",
    "    V_plot = ((v_test[:, frame:frame + 1] - v_pred.detach().numpy())**2).reshape(50, 100)\n",
    "    P_plot = ((p_test[:, frame:frame + 1] - p_pred.detach().numpy())**2).reshape(50, 100)\n",
    "    \n",
    "    ax[0].contourf(X_plot, Y_plot, U_plot, cmap='jet')\n",
    "    ax[1].contourf(X_plot, Y_plot, V_plot, cmap='jet')\n",
    "    ax[2].contourf(X_plot, Y_plot, P_plot, cmap='jet')\n",
    "     \n",
    "    ax[0].set_title(f'U velocity at t={t_star[frame][0]:.2f}')\n",
    "    ax[1].set_title(f'V velocity at t={t_star[frame][0]:.2f}')\n",
    "    ax[2].set_title(f'Pressure at t={t_star[frame][0]:.2f}')\n",
    "    ax[0].set_xlabel('y')\n",
    "    ax[0].set_ylabel('x')\n",
    "    ax[1].set_xlabel('y')\n",
    "    ax[1].set_ylabel('x')\n",
    "    ax[2].set_xlabel('y')\n",
    "    ax[2].set_ylabel('x')\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames=t_star.shape[0], interval=1)\n",
    "#ani.save('navier_stokes_animation_residual.gif')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bf9d17-016a-4d14-a7e6-461b28a6e3ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "9677320fd815cbb037e672c9f6c057423edde26b24c4c07629d38118fcd6ff36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
